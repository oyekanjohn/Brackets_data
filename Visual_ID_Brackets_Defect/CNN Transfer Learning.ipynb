{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tfa'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ec6e5a0fc07b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtfa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'load_ext'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tensorboard'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tfa'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "from keras.engine.topology import Layer\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import numpy.random as rng\n",
    "np.random.seed(1337)\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 256\n",
    "IMG_SIZE = (SIZE, SIZE)\n",
    "NUM_CHANNELS = 3\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Define training augmentations\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    #zca_whitening=True,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    brightness_range=[0.7, 1.3],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True)\n",
    "\n",
    "# Define validation augmentations\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create example augmented images\n",
    "img = load_img('F:/Work/University/Year 5/ACS6420_Advanced Project/Code/Data/Post Installation/Binary/Training/All Cases/Correct/Correct/IMG_1500.jpg')\n",
    "x = img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "i = 0\n",
    "for batch in train_datagen.flow(x, batch_size=1, save_to_dir='F:/Work/University/Year 5/ACS6420_Advanced Project/Code/Data/preview', save_format='jpeg'):\n",
    "    i+=1\n",
    "    if i > 9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 2 classes.\n",
      "Found 80 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'F:/Work/University/Year 5/ACS6420_Advanced Project/Code/Data/Post Installation/Binary/Training/All Cases/Both',\n",
    "    #'F:/Work/University/Year 5/ACS6420_Advanced Project/Code/Data/Post Installation/Binary/Training/Edge Cases/Both',\n",
    "    target_size=IMG_SIZE,\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "    seed=1,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    'F:/Work/University/Year 5/ACS6420_Advanced Project/Code/Data/Post Installation/Binary/Validation/All Cases/Both',\n",
    "    #'F:/Work/University/Year 5/ACS6420_Advanced Project/Code/Data/Post Installation/Binary/Validation/Edge Cases/Both',\n",
    "    target_size=IMG_SIZE,\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "    seed=2,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Convolutional Neural Network with VGG16 as Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_logdir = \"logs/scalars/\"\n",
    "for f in os.listdir(base_logdir):\n",
    "    file_path = os.path.join(base_logdir, f)\n",
    "    \n",
    "    shutil.rmtree(file_path)\n",
    "\n",
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               4194432   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 18,909,249\n",
      "Trainable params: 11,273,985\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = VGG16(include_top=False, input_shape=(SIZE, SIZE, NUM_CHANNELS))\n",
    "\n",
    "# Only retrain last block of VGG16 - 3 conv layers\n",
    "for layer in model.layers:\n",
    "    #if not layer.name.startswith('block5'):\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add own layers at end for task\n",
    "flat1 = Flatten()(model.layers[-1].output)\n",
    "dense1 = Dense(128, activation='relu', kernel_regularizer=l2(1E-4), bias_regularizer=l2(1E-3))(flat1)\n",
    "dropout1 = Dropout(0.5)(dense1)\n",
    "\n",
    "output = Dense(1, activation='sigmoid')(dropout1)\n",
    "\n",
    "model = Model(inputs=model.inputs, outputs=output)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "optimizer = Adam(lr=0.0001)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['accuracy', 'Precision', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.6769 - accuracy: 0.6250 - precision: 0.0000e+00 - recall: 0.0000e+00WARNING:tensorflow:From f:\\work\\university\\year 5\\acs6420_advanced project\\code\\siamese_env\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "2/6 [=========>....................] - ETA: 0s - loss: 0.7508 - accuracy: 0.5312 - precision: 0.4000 - recall: 0.3077        WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0580s vs `on_train_batch_end` time: 0.3630s). Check your callbacks.\n",
      "6/6 [==============================] - 14s 2s/step - loss: 0.8472 - accuracy: 0.6071 - precision: 0.6538 - recall: 0.4146 - val_loss: 1.0982 - val_accuracy: 0.5000 - val_precision: 0.5000 - val_recall: 1.0000\n",
      "Epoch 2/25\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.7314 - accuracy: 0.5714 - precision: 0.5455 - recall: 0.8571 - val_loss: 0.8129 - val_accuracy: 0.5250 - val_precision: 0.6250 - val_recall: 0.1250\n",
      "Epoch 3/25\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.5366 - accuracy: 0.6905 - precision: 0.9500 - recall: 0.4318 - val_loss: 0.6033 - val_accuracy: 0.6375 - val_precision: 0.5821 - val_recall: 0.9750\n",
      "Epoch 4/25\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.4694 - accuracy: 0.7619 - precision: 0.6833 - recall: 0.9762 - val_loss: 0.6234 - val_accuracy: 0.6875 - val_precision: 0.7419 - val_recall: 0.5750\n",
      "Epoch 5/25\n",
      "6/6 [==============================] - 9s 2s/step - loss: 0.3210 - accuracy: 0.8690 - precision: 0.9211 - recall: 0.8140 - val_loss: 0.7837 - val_accuracy: 0.6750 - val_precision: 0.6094 - val_recall: 0.9750\n",
      "Epoch 6/25\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.3196 - accuracy: 0.8333 - precision: 0.7692 - recall: 0.9524 - val_loss: 0.3734 - val_accuracy: 0.8500 - val_precision: 0.8182 - val_recall: 0.9000\n",
      "Epoch 7/25\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.2218 - accuracy: 0.9286 - precision: 0.9750 - recall: 0.8864 - val_loss: 0.8848 - val_accuracy: 0.6750 - val_precision: 0.6094 - val_recall: 0.9750\n",
      "Epoch 8/25\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.3362 - accuracy: 0.8810 - precision: 0.8810 - recall: 0.8810 - val_loss: 0.6880 - val_accuracy: 0.7125 - val_precision: 1.0000 - val_recall: 0.4250\n",
      "Epoch 9/25\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.3655 - accuracy: 0.8929 - precision: 0.9714 - recall: 0.8095 - val_loss: 0.7018 - val_accuracy: 0.6875 - val_precision: 0.6154 - val_recall: 1.0000\n",
      "Epoch 10/25\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.1798 - accuracy: 0.9405 - precision: 0.9167 - recall: 0.9778 - val_loss: 0.4819 - val_accuracy: 0.8375 - val_precision: 0.7647 - val_recall: 0.9750\n",
      "Epoch 11/25\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.1114 - accuracy: 0.9881 - precision: 1.0000 - recall: 0.9762 - val_loss: 0.3821 - val_accuracy: 0.8625 - val_precision: 0.8085 - val_recall: 0.9500\n",
      "Epoch 12/25\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.1263 - accuracy: 0.9643 - precision: 0.9737 - recall: 0.9487 - val_loss: 0.8964 - val_accuracy: 0.7625 - val_precision: 0.6780 - val_recall: 1.0000\n",
      "Epoch 13/25\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.1115 - accuracy: 0.9762 - precision: 0.9773 - recall: 0.9773 - val_loss: 0.5521 - val_accuracy: 0.8625 - val_precision: 0.8085 - val_recall: 0.9500\n",
      "Epoch 14/25\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.1113 - accuracy: 0.9762 - precision: 1.0000 - recall: 0.9545 - val_loss: 0.7351 - val_accuracy: 0.8125 - val_precision: 0.7273 - val_recall: 1.0000\n",
      "Epoch 15/25\n",
      "6/6 [==============================] - 9s 1s/step - loss: 0.0753 - accuracy: 0.9762 - precision: 0.9778 - recall: 0.9778 - val_loss: 0.2957 - val_accuracy: 0.8875 - val_precision: 0.8163 - val_recall: 1.0000\n",
      "Epoch 16/25\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.0541 - accuracy: 0.9762 - precision: 1.0000 - recall: 0.9556 - val_loss: 0.6657 - val_accuracy: 0.8500 - val_precision: 0.7692 - val_recall: 1.0000\n",
      "Epoch 17/25\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.1158 - accuracy: 0.9524 - precision: 0.9524 - recall: 0.9524 - val_loss: 0.1901 - val_accuracy: 0.9250 - val_precision: 0.8864 - val_recall: 0.9750\n",
      "Epoch 18/25\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.0493 - accuracy: 0.9881 - precision: 0.9762 - recall: 1.0000 - val_loss: 0.2212 - val_accuracy: 0.9000 - val_precision: 0.8478 - val_recall: 0.9750\n",
      "Epoch 19/25\n",
      "6/6 [==============================] - 9s 1s/step - loss: 0.0318 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.2828 - val_accuracy: 0.9000 - val_precision: 0.8478 - val_recall: 0.9750\n",
      "Epoch 20/25\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.0679 - accuracy: 0.9762 - precision: 0.9524 - recall: 1.0000 - val_loss: 0.3338 - val_accuracy: 0.8875 - val_precision: 0.8444 - val_recall: 0.9500\n",
      "Epoch 21/25\n",
      "6/6 [==============================] - 9s 1s/step - loss: 0.0309 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.7222 - val_accuracy: 0.8500 - val_precision: 0.7692 - val_recall: 1.0000\n",
      "Epoch 22/25\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.0295 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.6813 - val_accuracy: 0.8625 - val_precision: 0.7843 - val_recall: 1.0000\n",
      "Epoch 23/25\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.0426 - accuracy: 0.9762 - precision: 0.9767 - recall: 0.9767 - val_loss: 0.5253 - val_accuracy: 0.8875 - val_precision: 0.8298 - val_recall: 0.9750\n",
      "Epoch 24/25\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.1030 - accuracy: 0.9643 - precision: 0.9767 - recall: 0.9545 - val_loss: 1.3462 - val_accuracy: 0.8000 - val_precision: 0.7143 - val_recall: 1.0000\n",
      "Epoch 25/25\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.2106 - accuracy: 0.9286 - precision: 0.9730 - recall: 0.8780 - val_loss: 0.5806 - val_accuracy: 0.8500 - val_precision: 0.7692 - val_recall: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16859e5e588>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, steps_per_epoch=train_generator.samples//BATCH_SIZE, \n",
    "          validation_data=validation_generator, validation_steps=validation_generator.samples//BATCH_SIZE,\n",
    "          epochs=25,\n",
    "#           class_weight={0: 1, 1: 3},\n",
    "          callbacks=[tensorboard_callback], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 15136), started 0:01:16 ago. (Use '!kill 15136' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-28e89a4bce8fdaa\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-28e89a4bce8fdaa\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "modeldir = \"models/post_process/CNN/structure/\" + train_time\n",
    "weightdir = \"models/post_process/CNN/weights/\" + train_time\n",
    "\n",
    "with open(modeldir + \".json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "model.save_weights(weightdir + \".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Performance on Each Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path_root = 'F:/Work/University/Year 5/ACS6420_Advanced Project/Code/Data/Post Installation/Multiclass'\n",
    "test_category = '/Outside Guide_Incorrect Adhesion 2'\n",
    "test_path = test_path_root + test_category\n",
    "\n",
    "img_list = []\n",
    "for img in os.listdir(test_path):\n",
    "    img_array = cv2.imread(os.path.join(test_path, img))\n",
    "    img_array = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)\n",
    "    img_array = cv2.resize(img_array, IMG_SIZE)\n",
    "    img_array = img_array/255\n",
    "    img_list.append(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 \t 1.0\n",
      "1.0 \t 1.0\n",
      "1.0 \t 1.0\n",
      "1.0 \t 1.0\n",
      "1.0 \t 1.0\n",
      "1.0 \t 1.0\n",
      "1.0 \t 0.9999995\n",
      "1.0 \t 1.0\n",
      "1.0 \t 1.0\n",
      "1.0 \t 1.0\n",
      "1.0 \t 0.76496613\n",
      "0.0 \t 0.07216001\n",
      "1.0 \t 0.9996753\n"
     ]
    }
   ],
   "source": [
    "for img in img_list:\n",
    "    X = np.reshape(img, (1, SIZE, SIZE, NUM_CHANNELS))\n",
    "    prediction = model.predict(X)\n",
    "    print(round(prediction[-1][-1]), '\\t', prediction[-1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
